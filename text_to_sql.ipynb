{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "import re\n",
    "# if you are using SQLite\n",
    "sqlite_uri = 'sqlite:///./output.db' \n",
    "\n",
    "# if you are using MySQL\n",
    "# mysql_uri = 'mysql+mysqlconnector://root:admin@localhost:3306/test_db'\n",
    "\n",
    "db = SQLDatabase.from_uri(sqlite_uri)\n",
    "llm = Ollama(model = 'mistral:latest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCREATE TABLE store (\\n\\t\"Item_Identifier\" TEXT, \\n\\t\"Item_Weight\" REAL, \\n\\t\"Item_Fat_Content\" TEXT, \\n\\t\"Item_Visibility\" REAL, \\n\\t\"Item_Type\" TEXT, \\n\\t\"Item_MRP\" REAL, \\n\\t\"Outlet_Identifier\" TEXT, \\n\\t\"Outlet_Establishment_Year\" INTEGER, \\n\\t\"Outlet_Size\" TEXT, \\n\\t\"Outlet_Location_Type\" TEXT, \\n\\t\"Outlet_Type\" TEXT, \\n\\t\"Item_Outlet_Sales\" REAL\\n)\\n\\n/*\\n3 rows from store table:\\nItem_Identifier\\tItem_Weight\\tItem_Fat_Content\\tItem_Visibility\\tItem_Type\\tItem_MRP\\tOutlet_Identifier\\tOutlet_Establishment_Year\\tOutlet_Size\\tOutlet_Location_Type\\tOutlet_Type\\tItem_Outlet_Sales\\nFDA15\\t9.3\\tLow Fat\\t0.016047301\\tDairy\\t249.8092\\tOUT049\\t1999\\tMedium\\tTier 1\\tSupermarket Type1\\t3735.138\\nDRC01\\t5.92\\tRegular\\t0.019278216\\tSoft Drinks\\t48.2692\\tOUT018\\t2009\\tMedium\\tTier 3\\tSupermarket Type2\\t443.4228\\nFDN15\\t17.5\\tLow Fat\\t0.016760075\\tMeat\\t141.618\\tOUT049\\t1999\\tMedium\\tTier 1\\tSupermarket Type1\\t2097.27\\n*/'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(8523,)]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run('select count(*) from store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a sqllite query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n",
    "\n",
    "def run_query(query):\n",
    "    regex = r\"```sql\\n(.*?)\\n```\"\n",
    "    # Extract the query\n",
    "    match = re.search(regex, query, re.DOTALL)  # re.DOTALL allows matching across newlines\n",
    "    if match:\n",
    "        sql_query = match.group(1)\n",
    "        print('sql_query:', sql_query)\n",
    "        return db.run(f'{sql_query}')\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQL Result:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "full_template = \"\"\"Based on the table schema below, question, sqllite query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(full_template)\n",
    "\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm#.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = 'how many unique Item_Identifier are there in the database?'\n",
    "a = sql_chain.invoke({\"question\": user_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```sql\\nSELECT COUNT(DISTINCT Item_Identifier) FROM store;\\n```'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided table schema, question, SQL query, and SQL response, I can provide a natural language response to your question.\\n\\nThe available tables in the database are \"store\".'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = 'what are the available tables in the database'#'how many unique Item_Identifier are there in the database?'\n",
    "full_chain.invoke({\"question\": user_question})\n",
    "\n",
    "# 'There are 347 albums in the database.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChromaChatMessageHistory' from 'langchain_community.chat_message_histories' (/opt/homebrew/Caskroom/miniforge/base/envs/rag_env/lib/python3.9/site-packages/langchain_community/chat_message_histories/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_message_histories\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChromaChatMessageHistory\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine, inspect\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load environment variables\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChromaChatMessageHistory' from 'langchain_community.chat_message_histories' (/opt/homebrew/Caskroom/miniforge/base/envs/rag_env/lib/python3.9/site-packages/langchain_community/chat_message_histories/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import ChromaChatMessageHistory\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\")\n",
    "OLLAMA_MODEL = 'mistral:latest'\n",
    "DATABASE_URL = 'sqlite:///./output.db'   # e.g., 'sqlite:///example.db'\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = Ollama(model=OLLAMA_MODEL)\n",
    "\n",
    "# Initialize Chroma DB\n",
    "chroma_client = Chroma(persist_directory=\"path_to_chroma_db\", embedding_function=llm.embed_text)\n",
    "chroma_collection = chroma_client.get_collection(name=\"chatbot_conversations\")\n",
    "\n",
    "# Initialize chat history with Chroma DB\n",
    "chat_history = ChromaChatMessageHistory(chroma_collection=chroma_collection)\n",
    "\n",
    "# Initialize SQLAlchemy engine\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "def get_schema(_):\n",
    "    inspector = inspect(engine)\n",
    "    schema = {}\n",
    "    for table_name in inspector.get_table_names():\n",
    "        columns = inspector.get_columns(table_name)\n",
    "        schema[table_name] = [column['name'] for column in columns]\n",
    "    return schema\n",
    "\n",
    "def run_query(query):\n",
    "    regex = r\"```sql\\n(.*?)\\n```\"\n",
    "    # Extract the query\n",
    "    match = re.search(regex, query, re.DOTALL)  # re.DOTALL allows matching across newlines\n",
    "    if match:\n",
    "        sql_query = match.group(1)\n",
    "        print('sql_query:', sql_query)\n",
    "        conn = engine.connect()\n",
    "        results = conn.execute(sql_query).fetchall()\n",
    "        conn.close()\n",
    "        return results\n",
    "\n",
    "# Define the initial prompt template for generating SQL queries\n",
    "template = \"\"\"Based on the table schema below, write a sqlite query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Define the full prompt template for generating natural language responses\n",
    "full_template = \"\"\"Based on the table schema below, question, sqlite query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(full_template)\n",
    "\n",
    "# Define the full chain with context-aware history retrieval\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm  # .bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def handle_chat(message):\n",
    "    # Retrieve chat history\n",
    "    chat_history.add_message(message)\n",
    "    history_messages = chat_history.get_messages()\n",
    "    \n",
    "    # Prepare the input with history messages\n",
    "    input_data = {\n",
    "        \"question\": message,\n",
    "        \"history\": \"\\n\".join(history_messages)\n",
    "    }\n",
    "    \n",
    "    # Execute the full chain with context-aware input\n",
    "    response = full_chain(input_data)\n",
    "    \n",
    "    # Add the response to chat history\n",
    "    chat_history.add_message(response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        print(\"Bot:\", handle_chat(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Chroma' object has no attribute 'get_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize Chroma DB\u001b[39;00m\n\u001b[1;32m     24\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_function\u001b[38;5;241m=\u001b[39mFastEmbedEmbeddings) \n\u001b[0;32m---> 25\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_collection\u001b[49m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_conversations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Initialize SQLAlchemy engine\u001b[39;00m\n\u001b[1;32m     28\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(DATABASE_URL)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Chroma' object has no attribute 'get_collection'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from langchain_community.embeddings import FastEmbedEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "# load_dotenv()\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\")\n",
    "OLLAMA_MODEL = 'mistral:latest'\n",
    "DATABASE_URL = 'sqlite:///./output.db'   # e.g., 'sqlite:///example.db'\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = Ollama(model=OLLAMA_MODEL)\n",
    "\n",
    "# Initialize Chroma DB\n",
    "\n",
    "chroma_client = Chroma(persist_directory=\"path_to_chroma_db\", embedding_function=FastEmbedEmbeddings) \n",
    "chroma_collection = chroma_client.get_collection(name=\"chatbot_conversations\")\n",
    "\n",
    "# Initialize SQLAlchemy engine\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s2/jkxrxtzn6n777nh7h5w13yp80000gn/T/ipykernel_1301/1153085645.py:23: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  chroma_client = Chroma(persist_directory=\"path_to_chroma_db\", embedding_function=FastEmbedEmbeddings)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Chroma' object has no attribute 'get_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize Chroma DB\u001b[39;00m\n\u001b[1;32m     23\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_function\u001b[38;5;241m=\u001b[39mFastEmbedEmbeddings)\n\u001b[0;32m---> 24\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_collection\u001b[49m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_conversations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Initialize SQLAlchemy engine\u001b[39;00m\n\u001b[1;32m     27\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(DATABASE_URL)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Chroma' object has no attribute 'get_collection'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_schema(_):\n",
    "    inspector = inspect(engine)\n",
    "    schema = {}\n",
    "    for table_name in inspector.get_table_names():\n",
    "        columns = inspector.get_columns(table_name)\n",
    "        schema[table_name] = [column['name'] for column in columns]\n",
    "    return schema\n",
    "\n",
    "def run_query(query):\n",
    "    regex = r\"```sql\\n(.*?)\\n```\"\n",
    "    # Extract the query\n",
    "    match = re.search(regex, query, re.DOTALL)  # re.DOTALL allows matching across newlines\n",
    "    if match:\n",
    "        sql_query = match.group(1)\n",
    "        print('sql_query:', sql_query)\n",
    "        conn = engine.connect()\n",
    "        results = conn.execute(sql_query).fetchall()\n",
    "        conn.close()\n",
    "        return results\n",
    "\n",
    "# Define the initial prompt template for generating SQL queries\n",
    "template = \"\"\"Based on the table schema below, write a sqlite query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Define the full prompt template for generating natural language responses\n",
    "full_template = \"\"\"Based on the table schema below, question, sqlite query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(full_template)\n",
    "\n",
    "# Define the full chain with context-aware history retrieval\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"])\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm  # .bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def handle_chat(message):\n",
    "    # Retrieve chat history\n",
    "    chroma_collection.add_texts([message])\n",
    "    history_messages = [doc[\"text\"] for doc in chroma_collection.similarity_search(message, k=5)]\n",
    "    \n",
    "    # Prepare the input with history messages\n",
    "    input_data = {\n",
    "        \"question\": message,\n",
    "        \"history\": \"\\n\".join(history_messages)\n",
    "    }\n",
    "    \n",
    "    # Execute the full chain with context-aware input\n",
    "    response = full_chain(input_data)\n",
    "    \n",
    "    # Add the response to chat history\n",
    "    chroma_collection.add_texts([response])\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        print(\"Bot:\", handle_chat(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
